% !TEX encoding = UTF-8 Unicode
%!TEX root = ../Main/thesis.tex
% !TEX spellcheck = en-US
%%=========================================
\documentclass[../Main/thesis.tex]{subfiles}
\begin{document}
\chapter{Development}\label{ch:development}

\section{Requirements}%
\label{sec:requirements}
To establish requirements for the subsequent re-implementation of the
``visualizer'' component we will take a look at the current implementation, and
how the system works. The overarching requirements is the development and the
resulting project being a contribution to the Open-Source community.

\section{Rebuilder}\label{sec:development_rebuilders}
The purpose of the rebuilder is to watch for new packages, queue them, build the
package in a clean environment to reproduce the package, and then publish this
result so we can query them later when installing packages.

To achieve this we need to fulfill a few requirements:

\begin{enumerate}
    \item \label{itm:published} We need to know when a package is published.
    \item \label{itm:scheduler} Something needs to schedule the new packages.
    \item \label{itm:builder} We need to build the package in a clean environment.
    \item \label{itm:publish} We need to publish results of the built package.
    \item \label{itm:transport} We need to check the results when installing packages.
\end{enumerate}

It is important to remember that this system is only targeted Debian as
supporting is universally would require a lot of engineering effort and handling
of special cases.

\begin{figure}[H]
  \centering
  \begin{sequencediagram}
    \newthread{buildinfo}{buildinfo server}{}
    \newthread{scheduler}{scheduler}{}
    \newthread{redis}{redis}{}
    \newthread{builder}{builder}{}
    \newthread{visualizer}{visualizer}{}
    \begin{call}{scheduler}{NewBuildinfo()}{buildinfo}{}\end{call}

    \begin{call}{scheduler}{rpush}{redis}{}
        \postlevel
    \end{call}

    \prelevel\prelevel
    \setthreadbias{east}

    \begin{call}{builder}{rpop}{redis}{}
        \postlevel
    \end{call}

    \setthreadbias{center}
    \begin{callself}{builder}{build}{}
    \end{callself}
    \begin{messcall}{builder}{publish}{visualizer}{}\end{messcall}
  \end{sequencediagram}
\caption{rebuilder sequence diagram}
\label{lst:rebuilder_sequence_diagram}
\end{figure}


\subsection{buildinfo.debian.net}%
\label{sub:buildinfo_debian_net}
The goal is to rebuild packages released by Debian, but getting this information
directly for a Debian package mirror can be tedious. What we instead do is
relaying on the buildinfo server created by the Debian project to keep track of
all published buildinfo files from built packages. This gives us a canonical
view of all packages built by Debian infrastructure.

% TODO: Add refference to pull request
To utilize this service we need to keep a track of all newly submitted files,
however the current API does not support this. To get around this we submitted a
code change so we would be able to get all files submitted after a given
timestamp. As of writing this code change is not accepted.

The rebuilder system has instead relied on a copy of the server with the code
change included so we are able to monitor new buildinfo files.

\subsection{scheduler}%
\label{sub:scheduler}
The scheduler is a small service which monitors the endpoint and schedules any
new files found from the buildinfo server. Currently it pushes new package files
to redis, which is a very simple key value store, to help schedule the builders.
This enables us to add an arbitrary number of builders. This is important for a
few reasons. It helps scaling the system if its needed, and it also allows to
have builders with different architectures to build packages.

Because of builder constraints the current scheduler does not add builds on
other architectures then ``amd64''.

\subsection{builder}%
\label{sub:builder}
The builder consists of a service that queries redis after new items on a timer.
When new builds are dispatched, the build is done by utilizing the buildinfo
files as provided by the Debian build server. The build are done with the tool
``srebuild''.

``srebuild'' is a Perl script used to build packages in a clean environment.
With this environment the buildinfo is parsed and all missing dependencies are
acquired to recreate the package. The source packages, which contains the source
and the build files needed to build the package, is acquired from a mirror and
the build is done. When the build is done, the results are signed with a
cryptographic key, to verify that the build server did produce the files, and
then published to the visualizer.


\subsection{visualizer}%
\label{sub:visualizer}
The visualizer is the component which displays the rebuilt packages in a web UI.
The user is also able to fetch the buildinfo and linkmetadata files. The current
implementation is a short snippet of code backed by a sqlite database to aid in
displaying the needed webpages. The implemented API as seen in
\ref{api:old_visualizer} is simplistic and provides the needed features to let
users verify builds.


\begin{table}[H]
\footnotesize
\centering
\settowidth\tymin{\textbf{Endpoint}}
\setlength\extrarowheight{2pt}
\begin{tabulary}{\textwidth}{|l|L|l|L|}
\hline
    \textbf{Endpoint} & 
    \textbf{Type} & 
    \textbf{Parameters} & 
    \textbf{Description} \\
\hline
    /new\_build & POST$^1$ & metadata, buildinfo & Submit a new build \\  \hline
    /sources/<name> & GET & & Gets the available builds for a package \\  \hline
    /sources/<name>/<version>/buildinfo& GET & & Gets the BUILDINFO file for a build \\  \hline
    /sources/<name>/<version>/metadata & GET & & Gets the in-toto link metadata from a build \\  \hline
\end{tabulary}
\footnotesize{$^1$ Behind authentication}\\
\caption{Old visualizer API}
\label{api:old_visualizer}
\end{table}


\section{Project development}%
\label{sec:project_development}
We have now taken a look at the current implementation of the rebuilder system,
and how it integrates with the current iteration of the visualizer. In the next
session we will explain the development of the system for this thesis. It's
structured in 3 iterations of the visualizer, and an integration with the
existing APT transport written for the initial rebuilder system. We will in the
first iteration tackle the problem of maintaining compatibility with the current
system. The second iteration will be focusing on the implementation of the raw
merkle tree needed for transparency log. The third iteration will be the
abstracted logic on top of the transparency log, which the APT transport will be
utilizing when validating packages for the users.

\subsection{First Iteration: Visualizer}%
\label{sec:visualizer}
The first iteration is largely focused on recreating the functionality of the
current visualizer. The purpose of this component is to accept new rebuilds, the
in-toto link metadata file and buildinfo file produced by the rebuilder. This
needs to be displayed in a simple webpage and introduce no new features to
remain compatible.

In practice the visualizer only accepts two files, and displays an index of
these files. There are no processing being done except to figure the given
package name and version. The goal of this rewrite is to create a robust
foundation where we can improve on the current design, and in later iterations
build the needed data structures.


\begin{figure}[H]
\centering
\begin{tikzpicture}[
    EMP/.style={% Style for empatized boxes
        rectangle, line width =1pt,
        anchor=west,
        underline, % new property
        align=center,
        text=Black,
        minimum height=.8cm,
        text height=1.5ex,
            text depth=.25ex,
        fill=EMP,
        draw=black,
        },
    NOR/.style={% Style for normal boxes.
        rectangle, 
        line width =1pt,
        anchor=west,
        align=left,
        minimum height=.6cm,
        text height=1.5ex,
            text depth=.25ex,
            text=white,
        fill=NOR,
        draw=black,
        inner ysep=5pt
        },
    underline/.append style={% define new style property
        execute at begin node={%
            \setbox\ubox=\hbox\bgroup
            },
            execute at end node={%
                \egroup\uline{\box\ubox}%
                }
             },
    ] % Uff that is all the configuration for tickzpicture xD

 \def\Frame(#1)#2[#3]#4{%
  \begin{scope}[shift={(#1)}] 
      \node[font=\bf, anchor=west] (Title) at (-0.2,0.7) {#3}; 
       \edef\k{0}
       \edef\x{0}% Variable for named coordinate centering - below box
       \foreach \id/\style in {#4} {%enter sub frame data Name/Boxtype ,Name2/Boxtype | An space before Boxtype is needed 
            \node[\style] (h) at (\k pt,0) {\id}; %  % Draw a node depending on the variables.
            \pgfmathparse{\k+0.5*width{"\id"}+3.4pt} % Uses the textwidth to calculate named coordinate  
            \xdef\x{\pgfmathresult} % The resul is saved in the variable \x
            \draw (\x pt,-0.4) coordinate (\id#2); %Create a named coordinate concatenated: "sub frame data Name"+"identifier"
            \pgfmathparse{\k+width{"\id"}+6.8pt}% Calculate positiÃ³n for each subframe box.       
        \xdef\k{\pgfmathresult}% Save the value to be added to the next iteration value.
       }    
  \end{scope}
}
 \Frame(0,0){1}[BUILDINFO]{%first frame identified as 1 named EMPLOYEE
    Id/NOR,% see that it is necessary to add a space
    Created/NOR,
    Text/NOR,
    UUID/NOR,
    VersionId/EMP}; 

 \Frame(0,-2.5){2}[LINKMETADATA]{
    Id/NOR,
    Created/NOR,
    Text/NOR,
    UUID/NOR,
    VersionId/EMP}; 

 \Frame(0,-5){3}[VERSION]{
    Id/NOR,
    Created/NOR,
    Version/NOR,
    PackageId/EMP};

  \Frame(0,-7.5){4}[PACKAGE]{
    Id/NOR,
    Created/NOR,
    Name/NOR}; 

     \draw[thick,->,thick,>=latex]
        (PackageId3) -- ++(0,-.5) -- ++(0,0) coordinate (inter) 
        -- (Id4 -| inter) -- ++(0,-0.4) coordinate (inter)
        -- (Id4 |- inter) -- ++(0,0.5); %

     \draw[thick,->,thick,>=latex]
        (VersionId2) -- ++(0,-0.85) -- ++(.8,0) coordinate (inter) 
        -- (Id3 -| inter) -- ++(0,-0.2) coordinate (inter) 
        -- (Id3 |- inter) -- ++(0,0.3); %

     \draw[thick,->,thick,>=latex]
        (VersionId1) -- ++(0,-0.85) -- ++(1.5,0) coordinate (inter) 
        -- (Id3 -| inter) -- ++(0,-0.4) coordinate (inter) 
        -- (Id3 |- inter) -- ++(-.15,0) -- ++(0,0.5); %

\end{tikzpicture}
\caption{Database schema}
\label{fig:schema}
\end{figure}

The first step is to make sure the database format is correctly represented. The
previous iteration had a strict dependency on sqlite, which is a very simple
database stored in a single file. This works well for point of concept
implementations and where the database does not grow exceedingly large.

In the rewrite we will be utilizing an ORM for python, the sqlalchemy library.
This will allow us to define data models and instantiate them on top of
different database engines. The database structure itself closely copies the one
from the original implementation. The schema as displayed on~\ref{fig:schema},
page~\pageref{fig:schema}, represent the implemented model in the ORM.

The schema implements the model as follows; ``package'' can have multiple
``versions''. The models that belong to ``linkmetadata`` and ``buildinfo`` is
the tables containing the data itself. In the previous iteration these where
stored as plain text files, which is a less portable way of dealing with the
data. There can be multiple submissions for each version, so this relation is a
``One-to-Many`` relationship where one ``version'' can have multiple submissions
from rebuilders.

The ``UUID'' field found in the ``linkmetadata'' and ``buildinfo'' model is
mostly a hack. The main issue was to find the pairs of submissions without
over-complicating the database structure. One solution would be to create a new
table to associate the submissions. This would enable us to properly group them
later on an find the individual pairs. However, because of some time
constraints, and because the implementation of a new model would take some time,
the addition of an unique ``UUID'' for each submission is an easier alternative
that is simple to implement. This allows us to group the submissions for the
frontend later on.

It should be noted that the ORM handles the One-to-many and many-to-many
relationships. They are not explicitly included in the modeled schema for on 
for the sake of brevity.

% TODO: Forklar sqlalchemy implementasjon


\begin{figure}[H]
\begin{minted}[]{python}
class Version(db.Model):
    __tablename__ = "version"
    id = db.Column(
            db.Integer(),
            index=True, unique=True, 
            primary_key=True, autoincrement=True
        )

    created = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)
    version = db.Column(db.String(64), nullable=False)

    buildinfo = db.relationship("Buildinfo", back_populates="version")
    linkmetadata = db.relationship("LinkMetadata", back_populates="version")

    package_id = db.Column(db.Integer, db.ForeignKey("package.id"))
    package = db.relationship("Package", back_populates="version")

    def __repr__(self):
        return "<Version: {}>".format(self.version)
\end{minted}
\caption{Sqlalchemy code for Version model}
\label{fig:version-model}
\end{figure}

\subsection{API and Frontend}%
\label{sub:api_and_frontend}

To reimplement the API as can be seen in table~\ref{api:old_visualizer} on
page~\pageref{api:old_visualizer}, we need to create the needed routes for the
web service. This is being done by Flask, which is a webserver framework for
python. The same framework was utilized in the original implementation and
enables us to mainly substitute the code from the old database implementation,
to the one utilizing the ORM. There are two parts to this, one part needs to
return the plain-text elements for the APT transport, and one part needs to
render HTML webpages for the user too browse.


\begin{figure}[H]
\begin{minted}[]{python}
@app.route("/sources/<name>/<version>")
def all_sources_version(name, version):
    entries = (
        db.session.query(Version, Buildinfo, LinkMetadata)
        .filter(Package.name == name)
        .filter(Version.version == version)
        .filter(Buildinfo.uuid == LinkMetadata.uuid)
    ).all()
    return render_template("source.html", package=name, entries=entries)
\end{minted}
\caption{Python code for source.html}
\label{fig:python-source}
\end{figure}

\begin{figure}[H]
\begin{minted}[]{jinja}
<!DOCTYPE html>
<html>
  <head>
    <title> {{ package }} </title>
  </head>
  <body>
    <table>
      <tr>
        <th> Version </th>
        <th> Timestamp </th>
        <th> Buildinfo </th>
        <th> in-toto metadata </th>
      </tr>
      {% for entry in entries %}
      <tr>
        <td> {{ package }}-{{ entry[0].version }}</td>
        <td> {{entry[1].created }} </td>
        <td> 
            <a href="/sources/{{package}}/{{entry[0].version}}/buildinfo"> Link </a>
        </td>
        <td> 
            <a href="/sources/{{package}}/{{entry[0].version}}/metadata"> Link </a>
            </td>
      </tr>
      {% endfor %}
    </table>
  </body>
</html>

\end{minted}
\caption{jinja2 template for source.html}
\label{fig:jinja-source}
\end{figure}




\subsection{Second Iteration: Merkle Tree}%
\label{sub:merkle_tree}

\begin{table}[H]
\footnotesize
\centering
\settowidth\tymin{\textbf{Description}}
\setlength\extrarowheight{2pt}
\begin{tabulary}{1.0\textwidth}{|l|L|l|L|}
\hline
    \textbf{Endpoint} & 
    \textbf{Type} & 
    \textbf{Parameters} & 
    \textbf{Description} \\
\hline
    /api/log/stats & GET & & Statistics from the current tree \\ \hline
    /api/log/graphviz & GET & & Outputs the current tree in the dot format \\ \hline
    /api/log/root & GET & & Gets the latest signed tree root \\ \hline
    /api/log/tree/append & POST & JSON object & Appends a JSON object to the tree \\ \hline
    /api/log/tree/id/<id> & GET & & Gets the given Node object from the database with '``id''\\ \hline
    /api/log/tree/hash/<hash> & GET & & Gets the given Node object from the database with ``hash''\\ \hline
    /api/log/tree/leaf/<id> & GET & & Gets the given leaf from the database with matching ``leaf\_index''\\ \hline
    /api/log/tree/validate/id/<id> & GET & & Gets the audit proof for a leaf matching the given ``id''\\ \hline
    /api/log/tree/validate/hash/<hash> & GET & & Gets the audit proof for a leaf matching the given ``hash''\\ \hline
    %/api/log/tree/inclusion & POST & InclusionQuery & Provides the inclusion proof for the given query \\ \hline
    /api/log/tree/consistency & POST & ConsistencyQuery & Provides the consistency proof for the given query\\ \hline
\end{tabulary}
\caption{Second iteration: Transparency log API}
\label{api:transparency_log}
\end{table}


\begin{listing}[H]
\caption{JSON for consistency proof}
\label{lst:consistency proof}
\begin{minted}{json}
{}
\end{minted}
\end{listing}

\begin{listing}[H]
\caption{JSON for audit proof}
\label{lst:audit proof}
\begin{minted}{json}
{}
\end{minted}
\end{listing}



\subsection{Third Iteration: Transparency log overlay}%
\label{sub:transparency_overlay}

API entry definitions

\begin{listing}[H]
\caption{Entry definitions}
\label{lst:entrydefinitions}
\begin{minted}{go}
type Entry {
    Package string
    Version string
} 

type InclusionEntry {
    Entry
    Package         string
    Buildinfo       string
    Linkmetadata    string
}

type RevokeEntry {
    Entry 
    InclusionHash   string
    Reason          string
}
\end{minted}
\end{listing}


\begin{table}[hbtp]
\footnotesize
\centering
\settowidth\tymin{\textbf{Description}}
\setlength\extrarowheight{2pt}
\begin{tabulary}{1.0\textwidth}{|l|L|L|L|}
\hline
    \textbf{Endpoint} & 
    \textbf{Type} & 
    \textbf{Parameters} & 
    \textbf{Description} \\
\hline
    /api/rebuilder/submit & POST$^1$ & metadata, buildinfo& Implements something heyho lets go \\  \hline
    /api/rebuilder/revoke& POST$^1$ & leaf hash, reason, signature& Revokes the leaf with a reason  \\  \hline
    /api/rebuilder/fetch/<name>/<version>& GET & & Gets the entries for the given package \\  \hline
\end{tabulary}
\footnotesize{$^1$ Behind authentication}\\
\caption{Overlay API}
\label{api:Overlay API}
\end{table}


\subsection{APT Transport integration}\label{sec:apt_transport}

\begin{figure}[H]
  \centering
  \begin{sequencediagram}
    \newthread{A}{HTTP client}{}
    \newinst[1]{B}{intoto}{}
    \newinst[2]{C}{APT Server}{}
    \begin{messcall}{A}{100 Capabilities}{C}
        \begin{messcall}{C}{601 Configuration}{A}\end{messcall}
        \begin{messcall}{C}{600 URI Acquire}{A}\end{messcall}
        \begin{messcall}{A}{200 URI Start}{C}\end{messcall}
            \begin{messcall}{C}{201 URI Done}{B}
                \begin{sdblock}{Rebuilder verify}{}
                    \begin{messcall}{B}{201 URI Done}{A}\end{messcall}
                \end{sdblock}
            \end{messcall}
    \end{messcall}
  \end{sequencediagram}
\caption{intoto sequence diagram}
\label{lst:intoto_sequence_diagram}
\end{figure}

\begin{listing}[H]
\caption{Initial API request}
\label{lst:init_request}
\begin{align*}
& InitQuery\{Hash, Signature, LeafCount\} \to \\
& Response\{InclustionProof, ConsistencyProof, CurrentRoot\{ Hash, Signature\} \}
\end{align*}
\end{listing}


\begin{listing}[H]
\caption{Package query API request}
\label{lst:package_query_request}
\begin{equation*}
PkgQuery\{Package, Version\} \to Response\{InclusionEntry, Entry\dots \}
\end{equation*}
\end{listing}


\section{Testing}%
\label{sec:testing}



\blankpage
\end{document}
